import torch
import os
import sys

current_file = os.path.abspath(__file__) 
project_root = os.path.abspath(os.path.join(current_file, "..", "..")) # í˜„ì¬ ë””ë ‰í† ë¦¬ì— ë”°ë¼ ì´ ë¶€ë¶„ ìˆ˜ì •
sys.path.append(project_root)

from manage import PathManager
path_manager = PathManager()

# ì›í•˜ëŠ” ê²½ë¡œ ì¶”ê°€
sys.path.append(path_manager.get_path("config"))
sys.path.append(path_manager.get_path("logs"))
sys.path.append(path_manager.get_path("env"))
sys.path.append(path_manager.get_path("models"))
sys.path.append(path_manager.get_path("agents"))
sys.path.append(path_manager.get_path("data"))

try:
    from logs import log_manager
    from config import config_manager
    from env.stock_env import StockTradingEnv
    from models.transformer_model import StockTransformer
    from agents.ppo_agent import PPOAgent
    from data.data_loader import load_stock_data
    from config import config_manager
except Exception as e:
    print(f"ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")

class TrainingManager:
    """ í•™ìŠµëœ ëª¨ë¸ì„ ì €ì¥ ë° ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤ """
    def __init__(self, directory=None, filename="ppo_stock_trader.pth", checkpoint_filename="ppo_checkpoint.pth"):
        """
        TrainingManager ì´ˆê¸°í™”

        Args:
            directory (str, optional): ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬. ê¸°ë³¸ê°’ì€ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ `output` í´ë”.
            filename (str): ì €ì¥í•  ëª¨ë¸ íŒŒì¼ ì´ë¦„.
            checkpoint_filename (str): ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì´ë¦„.
        """
        if not hasattr(self, 'initialized'):  # ì¸ìŠ¤í„´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸
            default_directory = os.path.join(os.path.dirname(os.path.abspath(__file__)), "..", "output")
            self.directory = directory or default_directory  # âœ… ì‚¬ìš©ìê°€ ì§€ì •í•œ ê²½ë¡œê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
            self.filename = filename
            self.checkpoint_filename = checkpoint_filename
            self.save_path = os.path.join(self.directory, self.filename)
            self.checkpoint_path = os.path.join(self.directory, self.checkpoint_filename)
            log_manager.logger.debug(f"âœ… ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {self.save_path}")

            os.makedirs(self.directory, exist_ok=True)  # í´ë”ê°€ ì—†ìœ¼ë©´ ìë™ ìƒì„±
            self.initialized = True

    def save_model(self, model, episode=None):
        """
        ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ (ì „ì²´ ëª¨ë¸ì´ ì•„ë‹ˆë¼ ê°€ì¤‘ì¹˜ë§Œ ì €ì¥)

        Args:
            model (torch.nn.Module): ì €ì¥í•  ëª¨ë¸
            episode (int, optional): ì—í”¼ì†Œë“œ ë²ˆí˜¸ë¥¼ í¬í•¨í•˜ì—¬ ì €ì¥ (ê¸°ë³¸ê°’: None)
        """
        if episode is not None:
            filename = f"ppo_stock_trader_episode_{episode}.pth"  # âœ… ì—í”¼ì†Œë“œ ë²ˆí˜¸ í¬í•¨
        else:
            filename = self.filename

        save_path = os.path.join(self.directory, filename)

        try:
            torch.save(model.state_dict(), save_path)  # ğŸ”¥ ê°€ì¤‘ì¹˜ë§Œ ì €ì¥
            log_manager.logger.info(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_path}")
        except Exception as e:
            log_manager.logger.error(f"âŒ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")

    def save_checkpoint(self, model, optimizer, episode):
        """
        ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ (ëª¨ë¸ + ì˜µí‹°ë§ˆì´ì € + í˜„ì¬ ì§„í–‰ëœ ì—í”¼ì†Œë“œ í¬í•¨)

        Args:
            model (torch.nn.Module): ì €ì¥í•  ëª¨ë¸
            optimizer (torch.optim.Optimizer): ì˜µí‹°ë§ˆì´ì € ìƒíƒœ
            episode (int): í˜„ì¬ í•™ìŠµ ì§„í–‰ëœ ì—í”¼ì†Œë“œ
        """
        checkpoint = {
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'episode': episode
        }
        torch.save(checkpoint, self.checkpoint_path)
        log_manager.logger.info(f"âœ… ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì™„ë£Œ: {self.checkpoint_path} (Episode {episode})")

    def load_checkpoint(self, model, optimizer):
        """
        ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜

        Args:
            model (torch.nn.Module): ë¶ˆëŸ¬ì˜¬ ëª¨ë¸
            optimizer (torch.optim.Optimizer): ë¶ˆëŸ¬ì˜¬ ì˜µí‹°ë§ˆì´ì € ìƒíƒœ

        Returns:
            int: ë§ˆì§€ë§‰ í•™ìŠµëœ ì—í”¼ì†Œë“œ ë²ˆí˜¸ (ì—†ìœ¼ë©´ 0 ë°˜í™˜)
        """
        if os.path.exists(self.checkpoint_path):
            checkpoint = torch.load(self.checkpoint_path)
            model.load_state_dict(checkpoint['model_state_dict'], strict=False)
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            episode = checkpoint['episode']
            log_manager.logger.info(f"âœ… ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì™„ë£Œ: {self.checkpoint_path} (Episode {episode})")
            return episode
        else:
            log_manager.logger.info("âš ï¸ ì²´í¬í¬ì¸íŠ¸ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")
            return 0

def train_agent(env, agent, episodes, training_manager):
    """ PPO ì—ì´ì „íŠ¸ë¥¼ í•™ìŠµì‹œí‚¤ëŠ” í•¨ìˆ˜ """
    log_manager.logger.info(f"ğŸ¯ í•™ìŠµ ì‹œì‘")

    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ (ì´ì „ í•™ìŠµ ê¸°ë¡ì´ ìˆìœ¼ë©´ ì´ì–´ì„œ ì‹œì‘)
    start_episode = training_manager.load_checkpoint(agent.model, agent.optimizer)
    best_reward = float('-inf')  # ìµœê³  ë¦¬ì›Œë“œ ê¸°ë¡ ì´ˆê¸°í™”
    saveflag = False

    for episode in range(start_episode, episodes):
        state = env.reset()
        memory = []
        total_reward = 0

        for t in range(len(env.stock_data) - config_manager.get_observation_window()):
            action = agent.select_action(state)  # PPOAgentê°€ ì•¡ì…˜ ì„ íƒ
            next_state, reward, done, _ = env.step(action)
            memory.append((state, action, reward))
            state = next_state
            total_reward += reward

            if done or len(memory) >= agent.batch_size:
                agent.update(memory)  # PPO ì—…ë°ì´íŠ¸ ìˆ˜í–‰
                memory = []  # ë°°ì¹˜ í•™ìŠµ í›„ ë©”ëª¨ë¦¬ ì´ˆê¸°í™”

        final_portfolio_value = env.balance + (env.shares_held * env.stock_data[env.current_step, 0])
        log_manager.logger.debug(f"Episode {episode+1}/{episodes}, Total Reward: {total_reward}, final_portfolio_value: {final_portfolio_value:.2f}")

        # ë§¤ 100ë²ˆì§¸ ì—í”¼ì†Œë“œë§ˆë‹¤ ëª¨ë¸ê³¼ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        if (episode + 1) % 100 == 0:
            training_manager.save_model(agent.model, episode=(episode + 1))
            training_manager.save_checkpoint(agent.model, agent.optimizer, episode+1)  # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            saveflag = True
            log_manager.logger.info(f"âœ… ì²´í¬í¬ì¸íŠ¸ ë° ëª¨ë¸ ì €ì¥ ì™„ë£Œ (Episode {episode+1})")

         # í˜„ì¬ ì—í”¼ì†Œë“œì˜ ë³´ìƒì´ ìµœê³  ë³´ìƒ(best_reward)ë³´ë‹¤ ë†’ì„ ê²½ìš° ì €ì¥
        if saveflag == False and total_reward > best_reward:
            best_reward = total_reward  # ìµœê³  ë¦¬ì›Œë“œ ê°±ì‹ 
            training_manager.save_model(agent.model, episode=(episode + 1))
            training_manager.save_checkpoint(agent.model, agent.optimizer, episode + 1)  # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            log_manager.logger.info(f"âœ… ìµœê³  ë¦¬ì›Œë“œ ê°±ì‹ ! ëª¨ë¸ ì €ì¥ ì™„ë£Œ (Episode {episode+1})")

    # ìµœì¢… í•™ìŠµ ì™„ë£Œ í›„ ëª¨ë¸ ì €ì¥
    training_manager.save_model(agent.model)
    log_manager.logger.info(f"âœ… ìµœì¢… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {training_manager.save_path}")

if __name__ == "__main__":
    # âœ… TrainingManager ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    training_manager = TrainingManager()

    # âœ… ë°ì´í„° ë¡œë“œ
    data, input_dim = load_stock_data("data/csv/sp500_training_data.csv")

    # âœ… í™˜ê²½ ë° ëª¨ë¸ ìƒì„±
    env = StockTradingEnv(data)
    model = StockTransformer(input_dim=input_dim)
    agent = PPOAgent(model)

    # âœ… í•™ìŠµ ì‹œì‘
    train_agent(env, agent, episodes=config_manager.get_episodes(), training_manager=training_manager)
