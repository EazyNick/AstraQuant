{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to csv\\sp500_training_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to csv\\sp500_test_data.csv\n",
      "ğŸ“¥ Downloading AAPL training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to csv\\AAPL_training_data.csv\n",
      "ğŸ“¥ Downloading TSLA training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to csv\\TSLA_training_data.csv\n",
      "ğŸ“¥ Downloading GOOGL training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to csv\\GOOGL_training_data.csv\n",
      "ğŸ“¥ Downloading MSFT training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to csv\\MSFT_training_data.csv\n",
      "ğŸ“¥ Downloading AMZN training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to csv\\AMZN_training_data.csv\n",
      "ğŸ“¥ Downloading AAPL test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to csv\\AAPL_test_data.csv\n",
      "ğŸ“¥ Downloading TSLA test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to csv\\TSLA_test_data.csv\n",
      "ğŸ“¥ Downloading GOOGL test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to csv\\GOOGL_test_data.csv\n",
      "ğŸ“¥ Downloading MSFT test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to csv\\MSFT_test_data.csv\n",
      "ğŸ“¥ Downloading AMZN test data...\n",
      "Data saved to csv\\AMZN_test_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "# !pip install yfinance pandas\n",
    "\n",
    "\"\"\"\n",
    "í˜„ì¬ê°€ + ì´ë™ í‰ê· ì„ , ê±°ë˜ëŸ‰ ì´ë™ í‰ê· ì„  + 365ì¼, 180ì¼, 90ì¼, 30ì¼ ê¸°ê°„ ë‚´ ìµœê³ ì , ìµœì €ì  ë° ì—­ì‚¬ìƒ ì‹ ê³ ê°€, ìµœì €ê°€\n",
    "1ë¶„ë´‰ ë°ì´í„° + 1ë¶„ë´‰ ì´ë™ í‰ê· ì„ \n",
    "\n",
    "Date: ë‚ ì§œ (YYYY-MM-DD í˜•ì‹)\n",
    "Close: ì¢…ê°€\n",
    "Volume: ê±°ë˜ëŸ‰\n",
    "SMA_X: Xì¼ ë‹¨ìˆœ ì´ë™ í‰ê· ì„  (SMA)\n",
    "VMA_X: Xì¼ ê±°ë˜ëŸ‰ ì´ë™ í‰ê· ì„  (VMA)\n",
    "\"\"\"\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "\n",
    "project_dir = 'csv'\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "\n",
    "def calculate_moving_average(data, window):\n",
    "    \"\"\"\n",
    "    ì´ë™ í‰ê· ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜. ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° í˜„ì¬ê¹Œì§€ì˜ í‰ê· ì„ ì‚¬ìš©.\n",
    "\n",
    "    Args:\n",
    "        data (pd.Series): ì£¼ì‹ ì¢…ê°€ ë°ì´í„° ì‹œë¦¬ì¦ˆ.\n",
    "        window (int): ì´ë™ í‰ê· ì„ ê³„ì‚°í•  ê¸°ê°„.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: ì´ë™ í‰ê·  ë°ì´í„° ì‹œë¦¬ì¦ˆ.\n",
    "    \"\"\"\n",
    "    return data.rolling(window=window, min_periods=1).mean()\n",
    "\n",
    "def calculate_trend_line(x, y):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ê°œì˜ ì „ì €ì ì„ ê¸°ë°˜ìœ¼ë¡œ ì„ í˜• íšŒê·€ ì¶”ì„¸ì„ ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜.\n",
    "\n",
    "    Args:\n",
    "        x (pd.Series): ë‚ ì§œ ì¸ë±ìŠ¤ (ì •ìˆ˜í˜• ë³€í™˜ í•„ìš”).\n",
    "        y (pd.Series): ìµœì €ì  ë°ì´í„°.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: ê³„ì‚°ëœ ì¶”ì„¸ì„  ë°ì´í„°.\n",
    "    \"\"\"\n",
    "    x_numeric = np.arange(len(x))  # ë‚ ì§œ ì¸ë±ìŠ¤ë¥¼ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜ (0, 1, 2, ...)\n",
    "    slope, intercept, _, _, _ = linregress(x_numeric, y)  # ì„ í˜• íšŒê·€ ìˆ˜í–‰ (ê¸°ìš¸ê¸°ì™€ ì ˆí¸ ê³„ì‚°)\n",
    "    return slope * x_numeric + intercept  # y = mx + b í˜•íƒœì˜ ì¶”ì„¸ì„  ê°’ ë°˜í™˜\n",
    "\n",
    "\n",
    "def calculate_slope(data):\n",
    "    \"\"\"\n",
    "    ì´ë™ í‰ê· ì„ ì˜ ê¸°ìš¸ê¸°(ì „ì¼ ëŒ€ë¹„ ë³€í™”ëŸ‰)ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜.\n",
    "\n",
    "    Args:\n",
    "        data (pd.Series): ì´ë™ í‰ê·  ë°ì´í„° ì‹œë¦¬ì¦ˆ.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: ê¸°ìš¸ê¸° ë°ì´í„° ì‹œë¦¬ì¦ˆ.\n",
    "    \"\"\"\n",
    "    return data.diff() / 2 # (data[1] - data[0]) / 2\n",
    "\n",
    "def get_stock_data(ticker, start_date, end_date, interval='1d'):\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ ì£¼ì‹ ì½”ë“œì™€ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ì£¼ì‹ ë°ì´í„°ë¥¼ ë°›ì•„ì˜¤ëŠ” í•¨ìˆ˜.\n",
    "\n",
    "    Args:\n",
    "        ticker (str): ì£¼ì‹ ì½”ë“œ.\n",
    "        start_date (str): ë°ì´í„°ì˜ ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹).\n",
    "        end_date (str): ë°ì´í„°ì˜ ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹).\n",
    "        interval (str): ë°ì´í„° ê°„ê²© (1d, 1m ë“±).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: ì£¼ì‹ ë°ì´í„° í”„ë ˆì„.\n",
    "    \"\"\"\n",
    "    data = yf.download(ticker, start=start_date, end=end_date, interval=interval)\n",
    "    data = data[['Close', 'Volume']]  # ì¢…ê°€ ë° ê±°ë˜ëŸ‰ ë°ì´í„° ì‚¬ìš©\n",
    "    data = data.reset_index()\n",
    "    data.columns = ['Date', 'Close', 'Volume']\n",
    "\n",
    "    # NaN ê°’ì„ ì•ìª½ ê°’ìœ¼ë¡œ ì±„ìš°ê¸°\n",
    "    # data.ffill(inplace=True)\n",
    "    # data.bfill(inplace=True)  # ì•ìª½ì— ê°’ì´ ì—†ì„ ê²½ìš° ë’¤ìª½ ê°’ìœ¼ë¡œ ì±„ìš°ê¸°\n",
    "\n",
    "    # ì¶”ê°€ ë°ì´í„° ê³„ì‚°\n",
    "    data['730D_High'] = data['Close'].rolling(window=730, min_periods=1).max()\n",
    "    data['730D_Low'] = data['Close'].rolling(window=730, min_periods=1).min()\n",
    "    data['365D_High'] = data['Close'].rolling(window=365, min_periods=1).max()\n",
    "    data['365D_Low'] = data['Close'].rolling(window=365, min_periods=1).min()\n",
    "    data['180D_High'] = data['Close'].rolling(window=180, min_periods=1).max()\n",
    "    data['180D_Low'] = data['Close'].rolling(window=180, min_periods=1).min()\n",
    "    data['90D_High'] = data['Close'].rolling(window=90, min_periods=1).max()\n",
    "    data['90D_Low'] = data['Close'].rolling(window=90, min_periods=1).min()\n",
    "    data['30D_High'] = data['Close'].rolling(window=30, min_periods=1).max()\n",
    "    data['30D_Low'] = data['Close'].rolling(window=30, min_periods=1).min()\n",
    "    data['AllTime_High'] = data['Close'].cummax()\n",
    "    data['AllTime_Low'] = data['Close'].cummin()\n",
    "\n",
    "    # ì´ë™í‰ê· ì„  ë°ì´í„° ê³„ì‚°\n",
    "    ma_columns = {}\n",
    "    slope_columns = {}\n",
    "    for ma in [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 60] + list(range(70, 710, 10)):\n",
    "        ma_columns[f'SMA_{ma}'] = calculate_moving_average(data['Close'], ma)\n",
    "        ma_columns[f'VMA_{ma}'] = calculate_moving_average(data['Volume'], ma)\n",
    "        slope_columns[f'Slope_SMA_{ma}'] = calculate_slope(ma_columns[f'SMA_{ma}'])\n",
    "        slope_columns[f'Slope_VMA_{ma}'] = calculate_slope(ma_columns[f'VMA_{ma}'])\n",
    "\n",
    "    ma_df = pd.DataFrame(ma_columns)\n",
    "    slope_df = pd.DataFrame(slope_columns)\n",
    "    data = pd.concat([data, ma_df, slope_df], axis=1)\n",
    "\n",
    "    # ì „ì €ì  ê¸°ë°˜ ì¶”ì„¸ì„  ê³„ì‚° ë° í˜„ì¬ê°€ ì ‘ì´‰ ì—¬ë¶€ í™•ì¸\n",
    "    for period in ['730D_Low', '365D_Low', '180D_Low', '90D_Low', '30D_Low', 'AllTime_Low']:\n",
    "        lows_y = data[period].dropna()\n",
    "        lows_x = data['Date'].dropna().reset_index(drop=True).index[:len(lows_y)]  # ì •ìˆ˜ ì¸ë±ìŠ¤ ë³€í™˜ ë° ê¸¸ì´ ì¡°ì •\n",
    "        \n",
    "        if len(lows_x) > 1:\n",
    "            trend_values = calculate_trend_line(lows_x, lows_y)\n",
    "            data.loc[data.index[:len(trend_values)], f'Trend_Support_{period}'] = trend_values\n",
    "        else:\n",
    "            data[f'Trend_Support_{period}'] = np.nan\n",
    "        \n",
    "        # í˜„ì¬ê°€ê°€ í•´ë‹¹ ì¶”ì„¸ì„ ì— ë‹¿ì•˜ëŠ”ì§€ ì—¬ë¶€ í™•ì¸\n",
    "        data[f'Touch_Trend_Support_{period}'] = data['Close'] <= data[f'Trend_Support_{period}']\n",
    "\n",
    "    # ì „ê³ ì  ê¸°ë°˜ ì¶”ì„¸ì„  ê³„ì‚° ë° í˜„ì¬ê°€ ëŒíŒŒ ì—¬ë¶€ í™•ì¸\n",
    "    for period in ['730D_High', '365D_High', '180D_High', '90D_High', '30D_High', 'AllTime_High']:\n",
    "        highs_y = data[period].dropna()\n",
    "        highs_x = data['Date'].dropna().reset_index(drop=True).index[:len(highs_y)]  # ì •ìˆ˜ ì¸ë±ìŠ¤ ë³€í™˜ ë° ê¸¸ì´ ì¡°ì •\n",
    "        \n",
    "        if len(highs_x) > 1:\n",
    "            trend_values = calculate_trend_line(highs_x, highs_y)\n",
    "            data.loc[data.index[:len(trend_values)], f'Trend_Resistance_{period}'] = trend_values\n",
    "        else:\n",
    "            data[f'Trend_Resistance_{period}'] = np.nan\n",
    "        \n",
    "        # í˜„ì¬ê°€ê°€ í•´ë‹¹ ì €í•­ì„ ì— ë‹¿ì•˜ëŠ”ì§€ ì—¬ë¶€ í™•ì¸\n",
    "        data[f'Touch_Trend_Resistance_{period}'] = data['Close'] >= data[f'Trend_Resistance_{period}']\n",
    "\n",
    "    return data\n",
    "\n",
    "def save_data_to_csv(data, filename):\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): ì €ì¥í•  ë°ì´í„° í”„ë ˆì„.\n",
    "        filename (str): ì €ì¥í•  CSV íŒŒì¼ì˜ ì´ë¦„.\n",
    "    \"\"\"\n",
    "    data.to_csv(filename, index=False)\n",
    "    print(f'Data saved to {filename}')\n",
    "\n",
    "def fetch_and_save_stock_data(tickers, start_date, end_date, project_dir, data_type='training'):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ì£¼ì‹ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "    - tickers: ì¢…ëª© ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['AAPL', 'TSLA', 'GOOGL'])\n",
    "    - start_date: ì‹œì‘ ë‚ ì§œ ('YYYY-MM-DD')\n",
    "    - end_date: ì¢…ë£Œ ë‚ ì§œ ('YYYY-MM-DD')\n",
    "    - project_dir: ë°ì´í„° ì €ì¥ í´ë”\n",
    "    - data_type: 'training', 'test'\n",
    "    \"\"\"\n",
    "    for ticker in tickers:\n",
    "        filename = os.path.join(project_dir, f\"{ticker}_{data_type}_data.csv\")\n",
    "        print(f\"ğŸ“¥ Downloading {ticker} {data_type} data...\")\n",
    "\n",
    "        data = get_stock_data(ticker, start_date, end_date, interval='1d')\n",
    "        save_data_to_csv(data, filename)\n",
    "\n",
    "# S&P 500\n",
    "ticker = '^GSPC'\n",
    "# í•™ìŠµ ë°ì´í„°\n",
    "start_date = '2004-01-01'\n",
    "end_date = '2023-03-01'\n",
    "filename = os.path.join(project_dir, 'sp500_training_data.csv')\n",
    "data = get_stock_data(ticker, start_date, end_date, interval='1d')\n",
    "save_data_to_csv(data, filename)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°\n",
    "start_date = '2023-03-02'\n",
    "end_date = '2025-02-12'\n",
    "filename = os.path.join(project_dir, 'sp500_test_data.csv')\n",
    "data = get_stock_data(ticker, start_date, end_date, interval='1d')\n",
    "save_data_to_csv(data, filename)\n",
    "\n",
    "# ğŸ“Œ ì €ì¥í•  ì£¼ì‹ ë¦¬ìŠ¤íŠ¸\n",
    "tickers = ['AAPL', 'TSLA', 'GOOGL', 'MSFT', 'AMZN']\n",
    "\n",
    "# âœ… í•™ìŠµ ë°ì´í„° (2004-01-01 ~ 2023-03-01)\n",
    "fetch_and_save_stock_data(tickers, '2004-01-01', '2023-03-01', project_dir, data_type='training')\n",
    "\n",
    "# âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° (2023-03-02 ~ 2025-02-12)\n",
    "fetch_and_save_stock_data(tickers, '2023-03-02', '2025-02-12', project_dir, data_type='test')\n",
    "\n",
    "# # âœ… 1ë¶„ë´‰ ë°ì´í„° ì˜ˆì œ (ìµœê·¼ 30ì¼)\n",
    "# fetch_and_save_stock_data(['AAPL'], '2025-01-01', '2025-02-12', project_dir, interval='1m')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
