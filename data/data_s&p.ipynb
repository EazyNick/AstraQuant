{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to csv\\sp500_training_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to csv\\sp500_test_data.csv\n",
      "📥 Downloading AAPL training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to csv\\AAPL_training_data.csv\n",
      "📥 Downloading TSLA training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to csv\\TSLA_training_data.csv\n",
      "📥 Downloading GOOGL training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to csv\\GOOGL_training_data.csv\n",
      "📥 Downloading MSFT training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to csv\\MSFT_training_data.csv\n",
      "📥 Downloading AMZN training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to csv\\AMZN_training_data.csv\n",
      "📥 Downloading AAPL test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to csv\\AAPL_test_data.csv\n",
      "📥 Downloading TSLA test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to csv\\TSLA_test_data.csv\n",
      "📥 Downloading GOOGL test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to csv\\GOOGL_test_data.csv\n",
      "📥 Downloading MSFT test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to csv\\MSFT_test_data.csv\n",
      "📥 Downloading AMZN test data...\n",
      "Data saved to csv\\AMZN_test_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "# !pip install yfinance pandas\n",
    "\n",
    "\"\"\"\n",
    "현재가 + 이동 평균선, 거래량 이동 평균선 + 365일, 180일, 90일, 30일 기간 내 최고점, 최저점 및 역사상 신고가, 최저가\n",
    "1분봉 데이터 + 1분봉 이동 평균선\n",
    "\n",
    "Date: 날짜 (YYYY-MM-DD 형식)\n",
    "Close: 종가\n",
    "Volume: 거래량\n",
    "SMA_X: X일 단순 이동 평균선 (SMA)\n",
    "VMA_X: X일 거래량 이동 평균선 (VMA)\n",
    "\"\"\"\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "\n",
    "project_dir = 'csv'\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "\n",
    "def calculate_moving_average(data, window):\n",
    "    \"\"\"\n",
    "    이동 평균을 계산하는 함수. 데이터가 부족한 경우 현재까지의 평균을 사용.\n",
    "\n",
    "    Args:\n",
    "        data (pd.Series): 주식 종가 데이터 시리즈.\n",
    "        window (int): 이동 평균을 계산할 기간.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: 이동 평균 데이터 시리즈.\n",
    "    \"\"\"\n",
    "    return data.rolling(window=window, min_periods=1).mean()\n",
    "\n",
    "def calculate_trend_line(x, y):\n",
    "    \"\"\"\n",
    "    여러 개의 전저점을 기반으로 선형 회귀 추세선을 계산하는 함수.\n",
    "\n",
    "    Args:\n",
    "        x (pd.Series): 날짜 인덱스 (정수형 변환 필요).\n",
    "        y (pd.Series): 최저점 데이터.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: 계산된 추세선 데이터.\n",
    "    \"\"\"\n",
    "    x_numeric = np.arange(len(x))  # 날짜 인덱스를 정수형으로 변환 (0, 1, 2, ...)\n",
    "    slope, intercept, _, _, _ = linregress(x_numeric, y)  # 선형 회귀 수행 (기울기와 절편 계산)\n",
    "    return slope * x_numeric + intercept  # y = mx + b 형태의 추세선 값 반환\n",
    "\n",
    "\n",
    "def calculate_slope(data):\n",
    "    \"\"\"\n",
    "    이동 평균선의 기울기(전일 대비 변화량)를 계산하는 함수.\n",
    "\n",
    "    Args:\n",
    "        data (pd.Series): 이동 평균 데이터 시리즈.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: 기울기 데이터 시리즈.\n",
    "    \"\"\"\n",
    "    return data.diff() / 2 # (data[1] - data[0]) / 2\n",
    "\n",
    "def get_stock_data(ticker, start_date, end_date, interval='1d'):\n",
    "    \"\"\"\n",
    "    주어진 주식 코드와 기간에 해당하는 주식 데이터를 받아오는 함수.\n",
    "\n",
    "    Args:\n",
    "        ticker (str): 주식 코드.\n",
    "        start_date (str): 데이터의 시작 날짜 (YYYY-MM-DD 형식).\n",
    "        end_date (str): 데이터의 종료 날짜 (YYYY-MM-DD 형식).\n",
    "        interval (str): 데이터 간격 (1d, 1m 등).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 주식 데이터 프레임.\n",
    "    \"\"\"\n",
    "    data = yf.download(ticker, start=start_date, end=end_date, interval=interval)\n",
    "    data = data[['Close', 'Volume']]  # 종가 및 거래량 데이터 사용\n",
    "    data = data.reset_index()\n",
    "    data.columns = ['Date', 'Close', 'Volume']\n",
    "\n",
    "    # NaN 값을 앞쪽 값으로 채우기\n",
    "    # data.ffill(inplace=True)\n",
    "    # data.bfill(inplace=True)  # 앞쪽에 값이 없을 경우 뒤쪽 값으로 채우기\n",
    "\n",
    "    # 추가 데이터 계산\n",
    "    data['730D_High'] = data['Close'].rolling(window=730, min_periods=1).max()\n",
    "    data['730D_Low'] = data['Close'].rolling(window=730, min_periods=1).min()\n",
    "    data['365D_High'] = data['Close'].rolling(window=365, min_periods=1).max()\n",
    "    data['365D_Low'] = data['Close'].rolling(window=365, min_periods=1).min()\n",
    "    data['180D_High'] = data['Close'].rolling(window=180, min_periods=1).max()\n",
    "    data['180D_Low'] = data['Close'].rolling(window=180, min_periods=1).min()\n",
    "    data['90D_High'] = data['Close'].rolling(window=90, min_periods=1).max()\n",
    "    data['90D_Low'] = data['Close'].rolling(window=90, min_periods=1).min()\n",
    "    data['30D_High'] = data['Close'].rolling(window=30, min_periods=1).max()\n",
    "    data['30D_Low'] = data['Close'].rolling(window=30, min_periods=1).min()\n",
    "    data['AllTime_High'] = data['Close'].cummax()\n",
    "    data['AllTime_Low'] = data['Close'].cummin()\n",
    "\n",
    "    # 이동평균선 데이터 계산\n",
    "    ma_columns = {}\n",
    "    slope_columns = {}\n",
    "    for ma in [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 60] + list(range(70, 710, 10)):\n",
    "        ma_columns[f'SMA_{ma}'] = calculate_moving_average(data['Close'], ma)\n",
    "        ma_columns[f'VMA_{ma}'] = calculate_moving_average(data['Volume'], ma)\n",
    "        slope_columns[f'Slope_SMA_{ma}'] = calculate_slope(ma_columns[f'SMA_{ma}'])\n",
    "        slope_columns[f'Slope_VMA_{ma}'] = calculate_slope(ma_columns[f'VMA_{ma}'])\n",
    "\n",
    "    ma_df = pd.DataFrame(ma_columns)\n",
    "    slope_df = pd.DataFrame(slope_columns)\n",
    "    data = pd.concat([data, ma_df, slope_df], axis=1)\n",
    "\n",
    "    # 전저점 기반 추세선 계산 및 현재가 접촉 여부 확인\n",
    "    for period in ['730D_Low', '365D_Low', '180D_Low', '90D_Low', '30D_Low', 'AllTime_Low']:\n",
    "        lows_y = data[period].dropna()\n",
    "        lows_x = data['Date'].dropna().reset_index(drop=True).index[:len(lows_y)]  # 정수 인덱스 변환 및 길이 조정\n",
    "        \n",
    "        if len(lows_x) > 1:\n",
    "            trend_values = calculate_trend_line(lows_x, lows_y)\n",
    "            data.loc[data.index[:len(trend_values)], f'Trend_Support_{period}'] = trend_values\n",
    "        else:\n",
    "            data[f'Trend_Support_{period}'] = np.nan\n",
    "        \n",
    "        # 현재가가 해당 추세선에 닿았는지 여부 확인\n",
    "        data[f'Touch_Trend_Support_{period}'] = data['Close'] <= data[f'Trend_Support_{period}']\n",
    "\n",
    "    # 전고점 기반 추세선 계산 및 현재가 돌파 여부 확인\n",
    "    for period in ['730D_High', '365D_High', '180D_High', '90D_High', '30D_High', 'AllTime_High']:\n",
    "        highs_y = data[period].dropna()\n",
    "        highs_x = data['Date'].dropna().reset_index(drop=True).index[:len(highs_y)]  # 정수 인덱스 변환 및 길이 조정\n",
    "        \n",
    "        if len(highs_x) > 1:\n",
    "            trend_values = calculate_trend_line(highs_x, highs_y)\n",
    "            data.loc[data.index[:len(trend_values)], f'Trend_Resistance_{period}'] = trend_values\n",
    "        else:\n",
    "            data[f'Trend_Resistance_{period}'] = np.nan\n",
    "        \n",
    "        # 현재가가 해당 저항선에 닿았는지 여부 확인\n",
    "        data[f'Touch_Trend_Resistance_{period}'] = data['Close'] >= data[f'Trend_Resistance_{period}']\n",
    "\n",
    "    return data\n",
    "\n",
    "def save_data_to_csv(data, filename):\n",
    "    \"\"\"\n",
    "    주어진 데이터를 CSV 파일로 저장하는 함수.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): 저장할 데이터 프레임.\n",
    "        filename (str): 저장할 CSV 파일의 이름.\n",
    "    \"\"\"\n",
    "    data.to_csv(filename, index=False)\n",
    "    print(f'Data saved to {filename}')\n",
    "\n",
    "def fetch_and_save_stock_data(tickers, start_date, end_date, project_dir, data_type='training'):\n",
    "    \"\"\"\n",
    "    여러 주식 데이터를 가져와 CSV 파일로 저장\n",
    "    - tickers: 종목 리스트 (예: ['AAPL', 'TSLA', 'GOOGL'])\n",
    "    - start_date: 시작 날짜 ('YYYY-MM-DD')\n",
    "    - end_date: 종료 날짜 ('YYYY-MM-DD')\n",
    "    - project_dir: 데이터 저장 폴더\n",
    "    - data_type: 'training', 'test'\n",
    "    \"\"\"\n",
    "    for ticker in tickers:\n",
    "        filename = os.path.join(project_dir, f\"{ticker}_{data_type}_data.csv\")\n",
    "        print(f\"📥 Downloading {ticker} {data_type} data...\")\n",
    "\n",
    "        data = get_stock_data(ticker, start_date, end_date, interval='1d')\n",
    "        save_data_to_csv(data, filename)\n",
    "\n",
    "# S&P 500\n",
    "ticker = '^GSPC'\n",
    "# 학습 데이터\n",
    "start_date = '2004-01-01'\n",
    "end_date = '2023-03-01'\n",
    "filename = os.path.join(project_dir, 'sp500_training_data.csv')\n",
    "data = get_stock_data(ticker, start_date, end_date, interval='1d')\n",
    "save_data_to_csv(data, filename)\n",
    "\n",
    "# 테스트 데이터\n",
    "start_date = '2023-03-02'\n",
    "end_date = '2025-02-12'\n",
    "filename = os.path.join(project_dir, 'sp500_test_data.csv')\n",
    "data = get_stock_data(ticker, start_date, end_date, interval='1d')\n",
    "save_data_to_csv(data, filename)\n",
    "\n",
    "# 📌 저장할 주식 리스트\n",
    "tickers = ['AAPL', 'TSLA', 'GOOGL', 'MSFT', 'AMZN']\n",
    "\n",
    "# ✅ 학습 데이터 (2004-01-01 ~ 2023-03-01)\n",
    "fetch_and_save_stock_data(tickers, '2004-01-01', '2023-03-01', project_dir, data_type='training')\n",
    "\n",
    "# ✅ 테스트 데이터 (2023-03-02 ~ 2025-02-12)\n",
    "fetch_and_save_stock_data(tickers, '2023-03-02', '2025-02-12', project_dir, data_type='test')\n",
    "\n",
    "# # ✅ 1분봉 데이터 예제 (최근 30일)\n",
    "# fetch_and_save_stock_data(['AAPL'], '2025-01-01', '2025-02-12', project_dir, interval='1m')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
